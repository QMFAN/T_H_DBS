## 性能瓶颈结论
- 后端在批量处置中进行“逐条数据库写入与逐次扫描剩余异常”，导致分钟级耗时：
  - `import_tasks` 每条循环 `findOne` + `save`（约 6000 次）（backend/src/excel-import/excel-import.service.ts:343–351）
  - 每条循环调用 `pendingCountForTask`，Redis 实现为全局扫描键集合（约 6000 次）（backend/src/excel-import/excel-import.service.ts:346）
  - 批量覆盖时，逐条 `upsert` 单记录，未批量聚合（backend/src/excel-import/excel-import.service.ts:318）

## 目标
- 将“任务更新”和“覆盖写库”改为批量操作；将“剩余异常计数”改为 O(1) 查询；保证 6000 条在秒级完成。

## 具体改造
- 后端服务（ExcelImportService.bulkResolveAnomalies）
  1. 将 `resolved` 按 `taskNumericId` 分组，聚合每个任务的处置条数与覆盖写入记录：
     - 对于 `action=skip`：不写 `sensor_data`，每任务仅一次 `manualResolved += count`，一次性计算剩余并更新状态；一次 `save`
     - 对于 `action=overwrite`：将该任务的覆盖写库集合聚合为数组，按批次（如 1000 条）调用一次 `upsert`，减少往返与锁开销；随后一次性更新任务
  2. `pendingCountForTask` 改为每任务仅调用一次，不在循环中调用

- 临时存储（RedisAnomalyStoreService）
  1. 维护任务维度集合：新增键 `import:task:{taskId}:ids` 
     - `register` 时 `SADD`；`resolve`/`bulkResolve` 时 `SREM`；
     - 将 `pendingCountForTask(taskId)` 优化为 `SCARD import:task:{taskId}:ids`（O(1)），不再全局扫描
  2. `bulkResolve` 已实现 `MGET` + `pipeline(DEL/SREM)`；同时补充对任务集合的 `SREM`

- 代码路径
  - 服务批量更新与覆盖：backend/src/excel-import/excel-import.service.ts:318、343–351、346
  - Redis 存储集合维护：backend/src/excel-import/anomaly-store.redis.ts:41（register）、64（resolveOne）、83（bulkResolve）

## 验证步骤
1. 启动后端，上传形成 6000+ 重复条目
2. 执行“批量跳过”：
   - 预期接口耗时 < 2s；`pendingCount` 归零；`sensor_data` 数量不变
3. 执行“批量覆盖”：
   - 预期接口耗时 < 5s（取决于 MySQL upsert 与网络），数据正确覆盖

## 回滚与风险
- 如 Redis 集合维护出现不一致，可回退为内存存储或临时关闭任务集合优化，保留批量数据库写入逻辑即可显著降耗。
- 如单次 upsert 过大导致 MySQL 报包大小限制，可将批次调小（如 500 条）并观察耗时。